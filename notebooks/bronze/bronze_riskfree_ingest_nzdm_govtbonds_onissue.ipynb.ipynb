{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4e5f9adb-8841-4383-ad42-c45579935b33",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Data ETL Notebook\n",
    "\n",
    "**Layer**: Bronze\n",
    "\n",
    "**Domain**: Risk-free\n",
    "\n",
    "**Action**: Ingest NZDM New Zealand Government Securities Currently on Issue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b8387afd-2aaa-4891-89c6-0fbedd2220c2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "The purpose of this notebook is to ingest the file govtbonds-onissue-YYYY-mm-dd.xlsx from raw_data volume, apply SCD Type 2 data lineage, and write to a bronze data table with full history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7ba49020-450f-46a0-9280-1b58f73902ec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Install project requirements\n",
    "%pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "171cb1cc-0cd0-46e7-a0f4-9519f57d9bf8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "from pyspark.sql.functions import lit\n",
    "from delta.tables import DeltaTable\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7e66b152-ca8b-4197-8813-3f38c6976166",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define path for input data file\n",
    "source_directory = '/Volumes/workspace/riskfree_bronze/raw_data/'\n",
    "source_file_names = [f for f in os.listdir(source_directory) if os.path.isfile(os.path.join(source_directory, f))]\n",
    "source_file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "02034602-ac4b-4529-8892-43e1a3faad9b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Keep only valid source file names\n",
    "valid_files = [file for file in source_file_names if file.startswith('govtbonds-onissue-') and file.endswith('.xlsx')]\n",
    "source_file_names = [file for file in source_file_names if file in valid_files]\n",
    "source_file_names\n",
    "\n",
    "if not source_file_names:\n",
    "    dbutils.notebook.exit(\"No valid source files found.\")\n",
    "else:\n",
    "    print(source_file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "37009506-fb51-4759-b5cd-33f82cb449d1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ingestion_timestamp = datetime.datetime.now()\n",
    "print('Ingestion timestamp:', ingestion_timestamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "33ca1146-3147-4f60-b889-e13c1eaab33d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Ingest Nominal & Index-linked Bond Data into bronze table (append, SCD Type 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b5e29407-b98d-432a-8d23-12b9215d874d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def clean_column_name(col):\n",
    "    # Remove *, (, ), +, $, strip spaces, replace spaces and - with _, lowercase\n",
    "    col = re.sub(r'[*()+$]', '', col)\n",
    "    col = col.strip().replace(' ', '_').replace('-', '_').lower()\n",
    "    col = re.sub(r'_+', '_', col)  # Replace multiple underscores with one\n",
    "    return col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ee697da2-19cf-493d-8c1f-930e1823cc73",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "for file in source_file_names:    \n",
    "    \n",
    "    # Set location\n",
    "    excel_path = f\"{source_directory}{file}\"\n",
    "\n",
    "    # Imports & Config\n",
    "    sheet_name = \"Sheet1\"\n",
    "\n",
    "    # Load Excel Sheet\n",
    "    df = pd.read_excel(excel_path, sheet_name=sheet_name)\n",
    "\n",
    "    # Extract publish date\n",
    "    publish_date = df.iloc[0, 0]\n",
    "    publish_date = publish_date.replace('Published: ', '')\n",
    "    publish_date = datetime.strptime(publish_date, '%d %B %Y')\n",
    "    publish_date = publish_date.strftime('%Y-%m-%d')\n",
    "\n",
    "    # Extract as of date\n",
    "    as_of_date = df.columns[0]\n",
    "    as_of_date = as_of_date.replace('New Zealand Government Securities Currently on Issue as at: ', '')\n",
    "    as_of_date = datetime.strptime(as_of_date, '%d %B %Y')\n",
    "    as_of_date = as_of_date.strftime('%Y-%m-%d')\n",
    "\n",
    "    ### Non-linked Assets Amounts Data ###\n",
    "\n",
    "    # Extract as of nominals amounts data\n",
    "    start_row = df[df.iloc[:, 0] == 'Date first Issued'].index[0]\n",
    "    end_row = df.iloc[start_row:, 0].isnull().idxmax()\n",
    "    df_nominals = df.iloc[start_row:end_row].reset_index(drop=True)\n",
    "    df_nominals.columns = df_nominals.iloc[0]\n",
    "    df_nominals = df_nominals[1:].reset_index(drop=True)\n",
    "\n",
    "    df_nominals.columns = [clean_column_name(col) for col in df_nominals.columns]\n",
    "\n",
    "    # Add additional info\n",
    "    df_nominals[\"publish_date\"] = publish_date\n",
    "    df_nominals[\"as_of_date\"] = as_of_date\n",
    "    df_nominals[\"source_file_name\"] = file\n",
    "    df_nominals[\"ingestion_timestamp\"] = ingestion_timestamp\n",
    "\n",
    "    df_nominals[\"coupon\"] = df_nominals[\"coupon\"].astype(str)\n",
    "\n",
    "    # Convert to Spark and write to Delta\n",
    "    spark_df_nominals = spark.createDataFrame(df_nominals)\n",
    "\n",
    "    # Convert to Spark & Add SCD2 fields\n",
    "    spark_df_nominals = spark_df_nominals \\\n",
    "        .withColumn(\"effective_start\", lit(ingestion_timestamp)) \\\n",
    "        .withColumn(\"effective_end\", lit(None).cast(\"timestamp\")) \\\n",
    "        .withColumn(\"is_current\", lit(True))\n",
    "\n",
    "    # Create the Delta table if it does not exist\n",
    "    spark.sql(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS workspace.riskfree_bronze.nzdm_govtbonds_onissue (\n",
    "        date_first_issued STRING,\n",
    "        loan_prefix STRING,\n",
    "        coupon STRING,\n",
    "        maturity DATE,\n",
    "        total_amt_outstanding_incl_rb_eqc_sresl_m DOUBLE,\n",
    "        rbnz_m DOUBLE,\n",
    "        eqc_m DOUBLE,\n",
    "        sresl_m DOUBLE,\n",
    "        market_bonds_m DOUBLE,\n",
    "        publish_date STRING,\n",
    "        as_of_date DATE,\n",
    "        source_file_name STRING,\n",
    "        ingestion_timestamp TIMESTAMP,\n",
    "        effective_start TIMESTAMP,\n",
    "        effective_end TIMESTAMP,\n",
    "        is_current BOOLEAN\n",
    "    ) USING DELTA\n",
    "    \"\"\")\n",
    "\n",
    "    # SCD Type 2 Merge\n",
    "    delta_table = DeltaTable.forName(spark, 'workspace.riskfree_bronze.nzdm_govtbonds_onissue')\n",
    "    delta_table.alias(\"t\").merge(\n",
    "        spark_df_nominals.alias(\"s\"),\n",
    "        \"t.loan_prefix = s.loan_prefix AND t.is_current = true\"\n",
    "    ).whenMatchedUpdate(\n",
    "        condition=\"t.total_amt_outstanding_incl_rb_eqc_sresl_m != s.total_amt_outstanding_incl_rb_eqc_sresl_m AND t.rbnz_m != s.rbnz_m AND t.eqc_m != s.eqc_m AND t.sresl_m != s.sresl_m AND t.market_bonds_m != s.market_bonds_m AND t.coupon != s.coupon\",\n",
    "        set={\n",
    "            \"effective_end\": \"s.effective_start\",\n",
    "            \"is_current\": \"false\"\n",
    "        }\n",
    "    ).whenNotMatchedInsertAll().execute()\n",
    "\n",
    "    print(\"workspace.riskfree_bronze.nzdm_govtbonds_onissue \", file)\n",
    "\n",
    "    ### Linked Assets Amounts Data ###\n",
    "\n",
    "    # Extract as of nominals amounts data\n",
    "    start_row = df[df.iloc[:, 0] == 'Maturity'].index[0]\n",
    "    end_row = df.iloc[start_row:, 0].isnull().idxmax()\n",
    "    df_linked = df.iloc[start_row:end_row].reset_index(drop=True)\n",
    "    df_linked.columns = df_linked.iloc[0]\n",
    "    df_linked = df_linked[1:].reset_index(drop=True)\n",
    "\n",
    "    df_linked.columns = [clean_column_name(col) for col in df_linked.columns]\n",
    "\n",
    "    # Add additional info\n",
    "    df_linked[\"publish_date\"] = publish_date\n",
    "    df_linked[\"as_of_date\"] = as_of_date\n",
    "    df_linked[\"source_file_name\"] = file\n",
    "    df_linked[\"ingestion_timestamp\"] = ingestion_timestamp\n",
    "\n",
    "    # Convert to Spark and write to Delta\n",
    "    spark_df_linked = spark.createDataFrame(df_linked)\n",
    "\n",
    "    # Convert to Spark & Add SCD2 fields\n",
    "    spark_df_linked = spark_df_linked \\\n",
    "        .withColumn(\"effective_start\", lit(ingestion_timestamp)) \\\n",
    "        .withColumn(\"effective_end\", lit(None).cast(\"timestamp\")) \\\n",
    "        .withColumn(\"is_current\", lit(True))\n",
    "\n",
    "    # Create the Delta table if it does not exist\n",
    "    spark.sql(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS workspace.riskfree_bronze.nzdm_govtbonds_onissue_linked (\n",
    "        maturity DATE,\n",
    "        last_coupon DATE,\n",
    "        next_coupon DATE,\n",
    "        kt_1 DOUBLE,\n",
    "        p DOUBLE,\n",
    "        kt DOUBLE,\n",
    "        face_value DOUBLE,\n",
    "        indexation_value DOUBLE,\n",
    "        current_principal DOUBLE,\n",
    "        publish_date STRING,\n",
    "        as_of_date DATE,\n",
    "        source_file_name STRING,\n",
    "        ingestion_timestamp TIMESTAMP,\n",
    "        effective_start TIMESTAMP,\n",
    "        effective_end TIMESTAMP,\n",
    "        is_current BOOLEAN\n",
    "    ) USING DELTA\n",
    "    \"\"\")\n",
    "\n",
    "    # SCD Type 2 Merge\n",
    "    delta_table = DeltaTable.forName(spark, 'workspace.riskfree_bronze.nzdm_govtbonds_onissue_linked')\n",
    "    delta_table.alias(\"t\").merge(\n",
    "        spark_df_linked.alias(\"s\"),\n",
    "        \"t.maturity = s.maturity AND t.is_current = true\"\n",
    "    ).whenMatchedUpdate(\n",
    "        condition=\"t.kt_1 != s.kt_1 AND t.p != s.p AND t.kt != s.kt AND t.face_value != s.face_value AND t.indexation_value != s.indexation_value AND t.current_principal != s.current_principal\",\n",
    "        set={\n",
    "            \"effective_end\": \"s.effective_start\",\n",
    "            \"is_current\": \"false\"\n",
    "        }\n",
    "    ).whenNotMatchedInsertAll().execute()\n",
    "\n",
    "    print(\"workspace.riskfree_bronze.nzdm_govtbonds_onissue_linked \", file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b96f397c-411d-43c9-a7be-639c01520630",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Move the xlsx into archive folder with date name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ef569526-b4b3-4e28-ad1b-b094176b0903",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "for file in source_file_names:\n",
    "\n",
    "    # Set location\n",
    "    excel_path = f\"{source_directory}{file}\"\n",
    "\n",
    "    # Excel archive name\n",
    "    excel_path_archive = f\"/Volumes/workspace/riskfree_bronze/raw_data/archive/{file}\"\n",
    "\n",
    "    # Move the processed Excel file to the archive directory\n",
    "    dbutils.fs.mv(excel_path, excel_path_archive)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 8440540639228258,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "bronze_riskfree_ingest_nzdm_govtbonds_onissue.ipynb",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
